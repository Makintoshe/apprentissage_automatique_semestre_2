{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbea4b24",
   "metadata": {},
   "source": [
    "# Travail pratique n°2 d'apprentissage automatique 2 sur la regression logistique à une seule classe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c9b83",
   "metadata": {},
   "source": [
    "Réalisé par MULAPI TITA Ketsia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69c206",
   "metadata": {},
   "source": [
    "# Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a74e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcde566",
   "metadata": {},
   "source": [
    "# 1) Problème jouet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1228c6bd",
   "metadata": {},
   "source": [
    "### Générez une base de données synthétiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20edd3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Les n nombres de 300 points que contiennent les classes\n",
    "\n",
    "'''\n",
    "n = 300\n",
    "sigma = 0.7\n",
    "a = np.array([-1,-1])\n",
    "b = np.array([1,1])\n",
    "\n",
    "X1 = sigma * np.random.randn(n,2) + a\n",
    "X2 = sigma * np.random.randn(n,2) + b\n",
    "\n",
    "X = np.concatenate((X1,X2),axis=0)\n",
    "y = np.concatenate((np.zeros((n)),np.ones((n))), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef041fc",
   "metadata": {},
   "source": [
    "### Affichez le nuage de points pour obtenir un résultat similaire à celui de la figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79ffbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X1[:,0],X1[:,1],c = 'r', s= 7)\n",
    "plt.scatter(X2[:,0],X2[:,1],c = 'blue', s= 7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6a777f",
   "metadata": {},
   "source": [
    "## Avant d’implémenter votre propre estimation du modèle de regression logistique, vous allez tester celui de scikit-learn :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76418f08",
   "metadata": {},
   "source": [
    "#### Importez la modèle de régression logistique de scikit-learn 1 et entrainez le sur la base synthé-tique que vous venez de créer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877500a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fa430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44f8e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8fb89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a030f119",
   "metadata": {},
   "source": [
    "##### prédiction basée sur les classses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26016c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0468b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_pred[y_pred!=y]) ,\" est le nombre de mauvaise prédiction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3912fd0f",
   "metadata": {},
   "source": [
    "##### prédiction basée sur les prédictions qui sont des probabilités d'appartenance à une classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a98d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34126cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e4c9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "yy_pred_prob = np.zeros(y.shape).astype(\"int\")\n",
    "for i in range(y_pred_proba.shape[0]):\n",
    "    if(y_pred_proba[i,0]>y_pred_proba[i,1]):\n",
    "        yy_pred_prob[i] = 0\n",
    "    else :\n",
    "        yy_pred_prob[i] = 1\n",
    "        \n",
    "print(len(yy_pred_prob[yy_pred_prob!=y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b39cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = len(yy_pred_prob[yy_pred_prob!=y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4899940",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Conclusion : Avec Sklearn, dans les 2 cas, on a le même résultat : \"+str(err)+\" mauvaise prédictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedda217",
   "metadata": {},
   "source": [
    "## Affichez la fonction de décision du modèle, comme montré en figure 2. Pour cela, il faut :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bcb38a",
   "metadata": {},
   "source": [
    "#### 1. Générer une grille de points 2D à l’aide de la fonction mesh que nous donnons ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e9f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesh(X, h = 0.02):\n",
    "    x_min , x_max = X[:, 0]. min() - .5, X[:, 0]. max() + .5\n",
    "    y_min , y_max = X[:, 1]. min() - .5, X[:, 1]. max() + .5\n",
    "    xx , yy = np.meshgrid(np.arange(x_min , x_max , h), np.arange(y_min , y_max , h))\n",
    "    return np.c_[xx.ravel(), yy.ravel()], xx , yy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d748bf6d",
   "metadata": {},
   "source": [
    "#### Rassembler les prédictions du modèle pour chacun des points de cette grille"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87606dd",
   "metadata": {},
   "source": [
    "### Afficher le nuage de points de la base d’apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456113de",
   "metadata": {},
   "source": [
    "#### Afficher les frontières de décisions en utilisant la fonction contourf de Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf20dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ec2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_for_sklearn(X,y,model):\n",
    "    \n",
    "    zz, xx, yy = mesh(X)\n",
    "    #\n",
    "    Z = model.predict(zz)\n",
    "    ZZ = model.predict_proba(zz)  \n",
    "    #\n",
    "    Z = Z.reshape((-1,1))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    #\n",
    "    ZZ = ZZ[:,0].reshape(xx.shape)\n",
    "    #\n",
    "    \n",
    "    # L'arrière plan\n",
    "    colors1 = ('lightcoral', 'steelblue')\n",
    "    cmap_me1 = ListedColormap(colors1[:len(np.unique(y))])\n",
    "    # La frontière\n",
    "    colors2 = ('white','white')\n",
    "    cmap_me_f1 = ListedColormap(colors2[:len(np.unique(y))])\n",
    "    # Les points\n",
    "    colors3 = ('firebrick','royalblue')\n",
    "    cmap_me_back3 = ListedColormap(colors3[:len(np.unique(y))])\n",
    "    \n",
    "        \n",
    "    # sklearn\n",
    "    cm = plt.cm.RdBu\n",
    "    \n",
    "    plt.figure(0)\n",
    "    out = plt.contourf(xx, yy, Z, cmap=cm,alpha=0.65)\n",
    "    plt.contour(out, cmap=cmap_me_f1)\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, cmap=cmap_me_back3, edgecolors=\"k\")\n",
    "    plt.title(\" la fonction de décision si les prédictions sont des classes from sklearn\")\n",
    "    plt.show()   \n",
    "    \n",
    "    # L'arrière plan\n",
    "    colors4 = ('lightcoral','steelblue')\n",
    "    cmap_me4 = ListedColormap(colors4[:len(np.unique(y))])\n",
    "    # La frontière\n",
    "    colors5 = ('whitesmoke','white')\n",
    "    cmap_me_f2 = ListedColormap(colors5[:len(np.unique(y))])      \n",
    "    # Les points\n",
    "    colors6 = ('royalblue','firebrick')\n",
    "    cmap_me_back6 = ListedColormap(colors6[:len(np.unique(y))])  \n",
    "    \n",
    "    plt.figure(1)\n",
    "    out = plt.contourf(xx, yy, ZZ, cmap=cm,alpha=0.65)\n",
    "    #plt.contour(out,cmap=cmap_me_f2)\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, cmap=cmap_me_back6, edgecolors=\"k\")\n",
    "    plt.title(\" la fonction de décision si les prédictions sont des probabilités d’appartenance à la classe from sklearn\")    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9d9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "afficher_for_sklearn(X,y,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665ddde2",
   "metadata": {},
   "source": [
    "### FIGURE 2 – À gauche : la fonction de décision si les prédictions sont des classes. À droite : la fonction de décision si les prédictions sont des probabilités d’appartenance à la classe λ1\n",
    "\n",
    ". Implémentez le calcul du coût en complétant la fonction ci-dessous ci-dessous :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c15302d",
   "metadata": {},
   "source": [
    "## 2. Régression logistique sur le problème jouet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5f7c69",
   "metadata": {},
   "source": [
    "Implémentez le calcul du coût en complétant la fonction ci-dessous ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_cost(X, y, w):\n",
    "    z = X@w # z(n,1) = X(n,d)@w(d,1)\n",
    "    # insérer votre code ici : La fonction que l’on veut minimiser\n",
    "    cout = np.sum(np.log(1 + np.exp(-z))) + np.sum(y*z) # page 20\n",
    "    return cout # cout(n,1) =  (n,1) + ((n,1)*(n,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db855560",
   "metadata": {},
   "source": [
    ". Implémentez l’estimation des paramètres du modèle de regression logistique en utilisant la\n",
    "méthode de descente de gradient :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d273c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_grad_desc(X, y):\n",
    "    d = X.shape[1] \n",
    "    w = np.random.randn(d) \n",
    "    w = w.reshape((-1,1)) # w(d,1)\n",
    "    nb_iter = 100 # to tune\n",
    "    pas = 0.01 # to tune\n",
    "    beta = 0.9 # for backtracking if needed - to tune\n",
    "    for i in range(nb_iter): # 100\n",
    "        z = X@w # z(n,1) = X(n,d) @ w(d,1)\n",
    "        # insérer votre code ici : Gradient (page 21)\n",
    "        grad = X.T @ (y - (np.exp(-z) / (1 + np.exp(-z)))) # n(d,1) = X(d,n)@(y(n,1)-(z(n,1)/z(n,1)))\n",
    "        w = w - pas * grad # w (d,1) = w (d,1) - pas(1,1) * (d,1)\n",
    "    return w # on retourne w (d,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532ac2d",
   "metadata": {},
   "source": [
    "Affichez la fonction de décision et proposez un protocole judicieux permettant de tester la performance de votre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe6f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = logreg_grad_desc(X, y) # l'apprentissage w(d,1)\n",
    "cout = logreg_cost(X, y, W) # le cout cout(n,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b412c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3555ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_for_me_from_scratch(X,y,w):\n",
    "    '''\n",
    "    Cette Fonction de décision pour la regression logistiques, \n",
    "    permettant de tester le modèle ici, \n",
    "    représenté par les paramètres w\n",
    "    '''\n",
    "    # On peut d'abord chercher à observer ce qu'on obteine \n",
    "    # avec les données d'entraînement afin de comparer\n",
    "    # ce qu'on peut obtenir conformément à Sklearn.\n",
    "    \n",
    "    xtest_grid, xx, yy  = mesh(X)\n",
    "    z = xtest_grid@w\n",
    "    exps = np.exp(-z)\n",
    "    den = (1+exps)\n",
    "    Z = 1/den\n",
    "    Z = Z.reshape(xx.shape)    \n",
    "    \n",
    "    # sklearn\n",
    "    cm = plt.cm.RdBu\n",
    "    \n",
    "    # L'arrière plan\n",
    "    colors1 = ('lightcoral', 'steelblue')\n",
    "    cmap_me1 = ListedColormap(colors1[:len(np.unique(y))])\n",
    "    # La frontière\n",
    "    colors2 = ('white','white')\n",
    "    cmap_me_f1 = ListedColormap(colors2[:len(np.unique(y))])\n",
    "    # Les points\n",
    "    colors3 = ('firebrick','royalblue')\n",
    "    cmap_me_back3 = ListedColormap(colors3[:len(np.unique(y))])\n",
    "    \n",
    "    plt.figure(0)\n",
    "    out = plt.contourf(xx, yy, Z, cmap=cm,alpha=0.9)\n",
    "    plt.contour(out, cmap=cmap_me_f1)\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, cmap=cmap_me_back3, edgecolors=\"k\")\n",
    "    plt.title(\" la fonction de décision si les prédictions sont des probas (from scratch)\")\n",
    "    \n",
    "    plt.show() \n",
    "    \n",
    "    # On va chercher à créer cette fois ci, \n",
    "    # des données qui serviront de test, mais pour se faire, il faudrait\n",
    "    # que ces données réflètent notre réalité, c'est à dire\n",
    "    # que ces données doivent correspondres aux données d'entrianement\n",
    "    \n",
    "    n = 100 # On crée alors 100 exemples à tester\n",
    "    sigma = 0.7 # avec le même écart\n",
    "    \n",
    "    # Dans les mêmes intervals\n",
    "    Xtest1 = sigma * np.random.randn(n,2) + a\n",
    "    Xtest2 = sigma * np.random.randn(n,2) + b\n",
    "\n",
    "    X_test = np.concatenate((Xtest1,Xtest2),axis=0)\n",
    "    y_test = np.concatenate((np.zeros((n)),np.ones((n))), axis = 0)\n",
    "\n",
    "    Xtest_Grid, xxx, yyy  = mesh(X_test)\n",
    "    # Fonction de prédiction Sigmoïde : renvoie les probas\n",
    "    ZZ = 1/(1+ np.exp(-Xtest_Grid@w))\n",
    "    ZZ = ZZ.reshape(xxx.shape)\n",
    "    \n",
    "    # L'arrière plan\n",
    "    colors1 = ('lightcoral', 'steelblue')\n",
    "    cmap_me1 = ListedColormap(colors1[:len(np.unique(y))])\n",
    "    # La frontière\n",
    "    colors2 = ('white','white')\n",
    "    cmap_me_f1 = ListedColormap(colors2[:len(np.unique(y))])\n",
    "    # Les points\n",
    "    colors3 = ('firebrick','royalblue')\n",
    "    cmap_me_back3 = ListedColormap(colors3[:len(np.unique(y))])\n",
    "    \n",
    "    plt.figure(0)\n",
    "    out = plt.contourf(xxx, yyy, ZZ, cmap=cm,alpha=0.9)\n",
    "    plt.contour(out, cmap=cmap_me_f1)\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, cmap=cmap_me_back3, edgecolors=\"k\")\n",
    "    plt.title(\" la fonction de décision si les prédictions sont des probas (from scratch)\")\n",
    "    \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7716f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "afficher_for_me_from_scratch(X, y, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9026df",
   "metadata": {},
   "source": [
    "### 3. Diagnostique médical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837b6993",
   "metadata": {},
   "source": [
    "On cherche à prédire la survenue d’un cancer à partir de paramètres médicaux. Pour cela, vous allez\n",
    "utiliser la base de données breast_cancer de Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190fbbf",
   "metadata": {},
   "source": [
    "3.1. Proposez une méthodologie valide pour comparer votre algorithme de régression logistique à\n",
    "l’implémentation de scikit-learn. Les résultats seront présentés avec des taux de bonne classification moyen et des écart-types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386ff38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb63d21",
   "metadata": {},
   "source": [
    "#### Comparaison from SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf327a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09719f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],X[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0d2945",
   "metadata": {},
   "source": [
    "On voit que les données ne ne sont pas centré à l'origine (normalisé) et n'ont pas la même échelle (standardiser) alors, on peut centrer et réduires les données :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4937d681",
   "metadata": {},
   "source": [
    "3.1.1. Je normalise en suite mes données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - np.mean(X, axis=0))/np.std(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8041e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c7ee06",
   "metadata": {},
   "source": [
    "3.1.2. Je commence par séparer mes données en données de test et données dn'etraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f85e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainTest(X,y):\n",
    "    '''\n",
    "    renvoie X_train, X_test, y_train, y_test\n",
    "    X_trian, y_train : Nos données d'apprentissage\n",
    "    X_test, y_test : Nos données de test\n",
    "    '''\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5451a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = getTrainTest(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef26e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvComparaison(Model, X, y, kfolds):\n",
    "    scoreCV = cross_val_score(Model,X,y,cv=kfolds)\n",
    "    mean = np.mean(scoreCV)\n",
    "    std = np.std(scoreCV)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResult(model, m,s):\n",
    "    print(str(model)+\" Accuracy: \"+str(m)+\" (+/- \"+str(s)+\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5809d73f",
   "metadata": {},
   "source": [
    "### 3.1.3 utilisation de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146368bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_reg = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a84a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_reg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57ce07",
   "metadata": {},
   "source": [
    "On tolère donc un minimum d'erreur, ce qui implique que l'on ne va pas sur apprendre et qu'on va plus au moins bien classer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_sklearn(X_test,y_test,X_train,y_train, X, y, model):\n",
    "    \n",
    "    #\n",
    "    zz, xx, yy = mesh(X_test)\n",
    "    #\n",
    "    Z = model.predict(zz)\n",
    "    ZZ = model.predict_proba(zz)  \n",
    "    #\n",
    "    Z = Z.reshape((-1,1))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    #\n",
    "    ZZ = ZZ[:,0].reshape(xx.shape)\n",
    "    #\n",
    "    \n",
    "    # Mean, std\n",
    "    \n",
    "    zzz = cvComparaison(model, X_test, y_test, 5)\n",
    "    ZZZZ = cvComparaison(model, X_test, y_test, 5)\n",
    "    \n",
    "    \n",
    "    print(\"Ci-dessous, les focntions de décisions (classes, probas) avec leur mean (+/- std) respectif\")\n",
    "    \n",
    "    # L'arrière plan\n",
    "    colors1 = ('lightcoral', 'steelblue')\n",
    "    cmap_me1 = ListedColormap(colors1[:len(np.unique(y))])\n",
    "    # La frontière\n",
    "    colors2 = ('white','white')\n",
    "    cmap_me_f1 = ListedColormap(colors2[:len(np.unique(y))])\n",
    "    # Les points\n",
    "    colors3 = ('firebrick','royalblue')\n",
    "    cmap_me_back3 = ListedColormap(colors3[:len(np.unique(y))])\n",
    "    \n",
    "        \n",
    "    # sklearn\n",
    "    cm = plt.cm.RdBu\n",
    "    \n",
    "    plt.figure(0)\n",
    "    out = plt.contourf(xx, yy, Z, cmap=cm,alpha=0.65)\n",
    "    plt.contour(out, cmap=cmap_me_f1)\n",
    "    plt.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=cmap_me_back3, edgecolors=\"k\")\n",
    "    plt.title(\" la fonction de décision si les prédictions sont des classes from sklearn\")\n",
    "    plt.show()       \n",
    "    \n",
    "    printResult(model, zzz[0],zzz[1])\n",
    "    \n",
    "    # L'arrière plan\n",
    "    colors4 = ('lightcoral','steelblue')\n",
    "    cmap_me4 = ListedColormap(colors4[:len(np.unique(y))])\n",
    "    # La frontière\n",
    "    colors5 = ('whitesmoke','white')\n",
    "    cmap_me_f2 = ListedColormap(colors5[:len(np.unique(y))])      \n",
    "    # Les points\n",
    "    colors6 = ('royalblue','firebrick')\n",
    "    cmap_me_back6 = ListedColormap(colors6[:len(np.unique(y))])  \n",
    "    \n",
    "    plt.figure(1)\n",
    "    out = plt.contourf(xx, yy, ZZ, cmap=cm,alpha=0.65)\n",
    "    #plt.contour(out,cmap=cmap_me_f2)\n",
    "    plt.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=cmap_me_back6, edgecolors=\"k\")\n",
    "    plt.title(\" la fonction de décision si les prédictions sont des probabilités d’appartenance à la classe from sklearn\")    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    printResult(model, zzz[0],zzz[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c325a48",
   "metadata": {},
   "source": [
    "Ici, on test nos données X_test et y_test, à l'aide du modèle entraîné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e24ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "afficher_sklearn(X_test,y_test,X_train,y_train, X, y, model_log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daabcfe9",
   "metadata": {},
   "source": [
    "### Conclusion : \n",
    "\n",
    "On voit que le modèle de sklearn entraîné classe (décide) plutot bien les données, on a les mêmes moyennes et écarts types aussi bien avec le premier que le second. Et, le fait d'avoir tolérer un miniimum d'erreur, a pemris de ne pas sur apprendre et donc de bien décider."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb214e39",
   "metadata": {},
   "source": [
    "#### Comparaison from algo by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d87d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tx_Erreur(y, ypred):\n",
    "    n = len(y)\n",
    "    rejet = 0\n",
    "    erreur = 0\n",
    "    for i in range(n):\n",
    "        if y_pred[i] == 2:\n",
    "            rejet += 1\n",
    "        elif y_pred[i] != y[i]:\n",
    "            erreur += 1    \n",
    "    return erreur/n, rejet/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_probas_to_class(X_test, y, w):\n",
    "    z = np.zeros((X_test.shape[0],1))\n",
    "    z = X_test@w\n",
    "    y_pred = np.zeros(len(y))\n",
    "    p1, p2 = np.zeros(len(y)), np.zeros(len(y))\n",
    "    for i in range (len(X_test)):\n",
    "        p1 = 1/(1 + np.exp(-z[i]))\n",
    "        p2 = 1 - 1/(1+np.exp(z[i]))\n",
    "        if(p1[i] >= 0.7):\n",
    "            y_pred[i] = 0\n",
    "        elif(p2[i] < 0.3):\n",
    "            y_pred[i] = 1\n",
    "        else:  # zone de confusion !!!\n",
    "            y_pred[i] = 2\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc806f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = logreg_grad_desc(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24112e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def another_log_reg_by_me(X_test, y_test, X_train, y_train):\n",
    "    scores = []\n",
    "    d = X_train.shape[1]\n",
    "    W = logreg_grad_desc(X_train, y_train)\n",
    "    y_pred = from_probas_to_class(X_test, y_test, W)\n",
    "    rejet, erreur = tx_Erreur(y_test, y_pred)\n",
    "    scores.append(1 - erreur)\n",
    "    return np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed76409",
   "metadata": {},
   "outputs": [],
   "source": [
    "another_log_reg_by_me(X_test, y_test, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e394c672",
   "metadata": {},
   "source": [
    "3.2. Comparez maintenant avec un algorithme la regression logistique régularisée en utilisant l’implémentation de Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ec8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357308b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg = Lasso(alpha=0.1)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c547f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c5a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"le nombre d'erreur de prédiction est \", len(y_pred_lasso[y_pred_lasso!=y_test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cd862d",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949910ac",
   "metadata": {},
   "source": [
    "Notre modèle de regression logistique a sur appris et renvoie un score moyen de 1.\n",
    "\n",
    "Celui de sklearn est optimisé, il n'est pas mal ne sur apprend pas et renvoie un score moyen en 0.96 et 0.97\n",
    "\n",
    "Enfin la regression regularisé devrait être bonne mais lorsqu'elle n'est pas bien paramétré, elle n'est pas top."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec58e32",
   "metadata": {},
   "source": [
    "# Difficulté rencontrées :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91fd389",
   "metadata": {},
   "source": [
    "Tantôt le code fonctionne, tantôt il affiche une MemoryError\n",
    "parfois il ne parvient pas à faire de reshape.\n",
    "J'ai aussi rencontré un problème de np.exp overflow\n",
    "je ne sais pas pourquoi et ne peux donc pas faire autrement(...)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
